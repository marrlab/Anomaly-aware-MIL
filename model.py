import os
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
# OoD
from scipy.spatial import distance


class MILModel(nn.Module):
    def __init__(self):
        '''
        Anomaly-aware multiple instace learning model.
        '''
        super(MILModel, self).__init__()
        self.L = 500
        self.D = 128
        self.K = 1
        self.ClassCount = 5

        self.encoder = nn.Sequential(
            nn.Conv2d(256, 301, kernel_size=2, stride=2, padding=2),
            nn.ReLU(),
            nn.Conv2d(301, 500, kernel_size=2, stride=2),
            nn.ReLU(),
            nn.MaxPool2d(2, stride=2),
            nn.Conv2d(500, 650, kernel_size=2, stride=2),
            nn.ReLU()
        )

        self.feature_extractor_part2 = nn.Sequential(
            nn.Linear(650, self.L),
            nn.ReLU(),
        )

        self.attention = nn.Sequential(
            nn.Linear(self.L, self.D),
            nn.Tanh(),
            nn.Linear(self.D, self.K)
        )

        self.pool_conv = nn.Sequential(
            nn.Conv2d(2 * self.K, self.K, kernel_size=1)
        )

        self.classifier = nn.Sequential(
            nn.Linear(self.L * self.K, 10),
            nn.Linear(10, self.ClassCount),
        )

        self.sil_classifier = nn.Sequential(
            nn.Linear(self.L * 1, 32),
            nn.Linear(32, self.ClassCount)
        )

    def normalize(self,x):
        '''
        Normalize input value between 0 and 1.
        
        Input:
        - x (a vector or a matrix)
        
        Output:
        - normalized vector or matrix with values between 0 and 1
        '''
        return (x - np.min(x)) / np.ptp(x)

    def mahal_dist(self, data, GMM):
        '''
        Calculates the mahalanobis distance between data points to a distribution.
        
        Input:
        - data (vectors defining a datapoint for an instance in the latent representation)
        - GMM (fitted gaussian mixture model on the distribution of control instances in the latent representation)
        
        Output:
        - dists (a vector containing the distance of each data input to the GMM distribution)
        '''
        precision = GMM.precisions_
        center = GMM.means_
        dists = []
        for i in range(len(data)):
            dists.append(distance.mahalanobis(data[i].cpu().detach().numpy(), center, precision))
        dists = torch.from_numpy(np.array(dists))
        if torch.cuda.is_available():
            dists = dists.cuda()
        return dists


    def forward_MILSIL(self, feats, GMM, Healthy=0):

        h1 = self.encoder(feats)
        H = h1.view(-1, 650)
        H = self.feature_extractor_part2(H)  # NxL
        if Healthy == 1:
            return H

        # find attention
        A = self.attention(H)  # NxK
        A = torch.transpose(A, 1, 0)  # KxN
        A = F.softmax(A, dim=1)  # softmax over N

        # find Mahal distance wrt GMM
        D = self.mahal_dist(H, GMM)
        D = D.T  # 1xN
        D = F.softmax(D, dim=1).float()  # softmax over N

        # generate pooling weights
        P = torch.cat((A, D), 0)
        P = self.pool_conv(P.T.unsqueeze(dim=2).unsqueeze(dim=3))

        M = torch.mm(P.squeeze(dim=3).squeeze(dim=2).T, H)

        Y_prob = self.classifier(M)
        Y_sil_prob = self.sil_classifier(H)

        return Y_prob, A, D, Y_sil_prob, M



    def calculate_loss_MILSIL(self, Y_prob, Y_sil_prob, label, sil_target):
        '''
        Calculates loss value.
        
        Input:
        - Y_prob (bag class predicted by the model)
        - Y_sil_prob (instance label predicted by the model)
        - label (ground truth for bag label)
        - sil_target (noisy instance label which is generated by attrebuting bag label to all instances)
        
        Output:
        - mil_bce_loss (bag classification loss)
        - sil_loss (instance classification loss)
        '''
        celoss = nn.CrossEntropyLoss()

        sil_bce_loss = celoss(Y_sil_prob, sil_target.squeeze())
        sil_loss = sil_bce_loss

        mil_bce_loss = celoss(Y_prob, label)

        return mil_bce_loss, sil_loss

    def save(self, modelname, modelDir="Model"):
        '''
        Saves model parameters.
        
        Input:
        - modelname (name of the learned model)
        - modelDir (directory address for saving model learned parameters)
        '''
        filename = modelname + "-" + time.strftime("%Y%m%d-%H%M%S") + ".mdl"
        path = os.path.join(modelDir, filename)
        torch.save(self, path)

    def load_latest(self, modelDir="Model", modelname=[]):
        '''
        Loads the latest update of model parameters.
        
        Input:
        - modelDir (directory address for saving model learned parameters)
        - modelname (name of the learned model)
        
        Output:
        - model with the latest update of parameters
        '''
        if modelname == []:
            model_name = sorted(os.listdir(modelDir), reverse=True)[0]
        else:
            model_name = modelname

        return torch.load(os.path.join(modelDir, model_name), map_location=torch.device('cpu'))
